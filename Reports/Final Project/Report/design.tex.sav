\section{Design of REACH}

\subsection{Hardware design of REACH}


\subsection{Building the Grip Classifier}
In addition to the hardware implementations by selecting appropriate force sensors and locating them in the appropriate places around the mobile device, we also build the classifier for the hand grip. In this section, we discuss how we collect force sensor values from mobile device for training and how we implement the classifier for grip pattern detection. We then used the model to predict the pattern in realtime manner. 
\par
We selected three grip pattern classes in our prototype: Hold, Squeeze, and Reach. In Hold, the subject holds the device without any activity on device. In Squeeze, the subject is applying the squeeze-force on the device and in Reach, the subject is moving his thumb finger to reach the top of the device. After we identified the grip pattern classes, we collected the training data from 3 subjects. Each subject was asked to perform Hold, Squeeze, and Reach for 3 times. The 12 force sensors around the device continuously generated data at $$$$Hz 


 The touch sensor chip continuously generated
the data at 30Hz, and we averaged the 15 touch data
(over 0.5 second) collected during the device was held still.
Hence the training data from each grip trial was composed
of 64 numeric fields for touch sensor readings. The final
training data was composed of 250 instances for each of the
8 grip patterns.

We used the Weka (Witten & Frank 2005) machine learning
library for the grip pattern classifiers. Specifically, we
trained naive Bayes and support vector machine classifiers
on the training data gathered through the process described
above. All the training was done off-line — the classifier
was trained on a desktop computer and then the parameters
were extracted to implement the embedded versions of the
classifiers (classification only) to be deployed into the prototype
device.




    